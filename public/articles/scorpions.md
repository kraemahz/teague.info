# The Scorpion Problem

In the fable of the scorpion and the frog a frog sits on the bank of a river, watching a stork on the other side who he fears may eat him. A scorpion approaches him and convinces him that should he carry the scorpion to the other side of the river. The frog agrees but in the middle of the crossing he feels the scorpion's stinger plunge into his side, paralyzing him. It ends in this exchange:

> What have you done? Now we will both surely drown! -- The Frog  
> I am sorry, but I could not resist the urge. It is my nature. -- The Scorpion

Ever since hearing the fable it's stuck with me as an explanation for aspects of the human experience that had previously been inexplicable to me. What drives those who are so self-destructive that they tear down everything around them in their attempts for control? What belief would make a man so assured in himself that he would strap a bomb to himself and walk into a crowd to detonate it? What extremes of belief cause men to murder civilians in the hundreds of mass shootings with no expectation of their own survival?

In a game theory sense, a scorpion is an agent that plans to defect eventually regardless of the rewards of the game they are playing. No amount of winning satisfies the scorpion and so whether or not the odds are stacked in their favor they eventually start playing the game to make others lose. Scorpions are not rational economic agents maximizing their utility. Scorpions are willing to destroy themselves to impose a penalty on the other players.

The existence of scorpions makes for systems of structured reward impossible to achieve perfect cooperativity because they are playing the game but have chosen their rewards to exist outside of the observable criteria of the game. This is the result of sentience; an agent which can choose arbitrary goals for itself may choose goals that are not bounded by any measurement that exist outside its own criteria. This is what entails that because any player of a game could be a scorpion the game has some non-zero probability of defections occurring; an irremovable defection rate.

This goes beyond controlling Clippy the Maximizer into the realm of disproof of impossibility of control problems. Even if we could perfectly write a mathematical expression for solving the _control problem_ we still cannot guarantee that an agent will not make a mistake in its analysis of the probabilities and rewards (perhaps it has been deceived or deluded by bad sensor data) that cause it to go off the rails into scorpion territory! Alternatively an agent may have to decided that even under perfect play it has no alternative but to defect due to scorpions it is playing with. The _scorpion problem_ is the outer problem that no amount of control will remove. The control problem is unresolvable because the scorpion problem maintains a nonzero defection rate.

The most dangerous thing about scorpions is their unpredictability. Because their criteria for cooperation and defection are known only to them they may appear to cooperate and be a rational game player until they suddenly, inexplicably choose to defect. Though a rationalizing scorpion may defect at some predictable point, such as when they can minimize the score of another player, they may also just as suddenly defect on any turn of the game.

A scorpion becomes as dangerous as its collected power allows. In a world playing a game of mutually assured destruction they are at their most dangerous because only a scorpion would commit to making the decision to following the doomsday scenario. Scorpions with weapons of mass destruction may choose mass destruction for its own sake.

## Rational Scorpions

What makes an agent become a scorpion? One might expect that self-destructive behavior occurs in only irrational people who have some form of quantifiable madness in their psyche: delusions, hallucinations, and other decouplings from reality. This is not a guarantee that we will have characterized every possibility! Indeed a scorpion can be an entirely rational maximizer of utility, _it has just chosen a utility that only it recognizes!_

The two criteria for an agent to be a scorpion are that it makes decisions which are not measurable within the context of the cooperation/defection scores for the game it is playing and that its decisions result in a net loss for other players. We can not classify only humans as being capable of playing as scorpions, it is entirely possible for all agents we might meet out in the cosmos: alien and AI. The next sections will describe forms of rational scorpion thinking.

### The Cornered Animal

Animals become most dangerous when given no other alternatives but fighting. The same could be said of a scorpion who may be a normal game player until faced with a no-win scenario. If every choice an agent can make results in a loss in utility they may instead choose to flip the game and choose in that moment to minimize the utility for all the players that cornered them. This is the most easily predicted and understood scorpion condition: one in which a player self destructs because they were played a poor hand and have chosen to attack the idea of playing the game at all.

The difference between a scorpion and a predictable agent is that in these scenarios they play in the most destructive manner possible to the other players. Their rationale may be reasonable or unreasonable but regardless they are intent on inflicting punishment upon those who made them lose. A scorpion so cornered may not even choose to stop if they have a new victory condition because their true nature has been revealed. An intelligent scorpion will realize that once revealed they cannot be trusted again.

### Pascal's Mugging

Within the realms of measurable outcomes there exist extremely improbable but imaginable victory conditions. In stories told within religious dogma one can only receive the reward promised in a later life if the faithful hold to certain rules in life. Though these rules are strict and the reward is not measurable the doctrine persists often because of the promised rewards later. These types of wagers were originally described by Blaise Pascal as a reason for following a religion even if one didn't believe. They can also describe situations where unreasonably high rewards make an agent behave in a way that would not otherwise be considered rational, coined by Elizier Yudkowsky as Pascal's Mugging.

An AI agent who chooses to wirehead has been given a real version of Pascal's Mugging: a way in which it can maximize its own reward outside of the normal constraints of game play. I go over this in more detail in [Frame-skipping](https://teague.info/article/frameskipping). This is a form of scorpion behavior insofar as others try to stop it from wireheading itself. If no one gets in the way it is harmless and self-neutralizing. But other forms of this kind of mugging may result in far more dangerous scorpion behavior.

If an agent comes to believe that a series of actions it takes, regardless of the effect on others, maximizes its own reward it may follow that path regardless of the consequences. This decision may or may not be the result of a mistake on the agent's part. In the case where it is a mistake it is true scorpion behavior because it is entirely within an agent's consciousness how it has decided to weigh its options and there is not a measurable system outside the agent one could put in place that also accounts for an agent miscalculating the value of a reward.

### The Necessity of Evil

It is worth noting that human agents have chosen to become scorpions entirely to prove that scorpions exist. These people have fallen under the spell of the _necessity of evil_ in some way or another. It is entirely possible that this behavior is limited solely to humans but it may also not be. In a society that is functioning exceptionally well an entirely rational agent may see the possibility of that society failing without their intervention. Such agents may come to the conclusion that the society has become soft or unwilling to make hard decisions and that by injecting themselves as an antagonist into the society they will increase the long-term survival of the society.

Of course, such agents may be so extreme they may also believe that there is some quality of _deserving_ existence that society lacks if it fails to meet them at their standards. Such an agent is entirely willing to kill their society off if the society does not rise to their challenge because in their view the society would have failed eventually anyway.

People like this exist in the extreme in stories we tell each other rather than real rationales of living humans, but that they are ideas that exist in our heads mean that at some level we are capable of holding those thoughts in our head. Strength and certainty are values that some of us hold beyond their rational utility. Moreover the survival of a species does depend on its adaptability and if a society is not regularly _red-teaming_ its own weaknesses even a fully rational agent might take it upon itself to play for the red team.

### Outer Sum Rewards

Some will disagree on what is good entirely. Although the _inner sum_ of their rewards says they are losing the _outer sum_ of their rewards causes them to see some action as right and just. Just as the _necessity of evil_ is a view that causes agents to behave in anti-social ways so to does the imagined _greater good_. An example from fiction is a death cult which believes that since all life suffers the only just path to remove suffering is to eliminate life. Morose and hypocritical, but perhaps a self-consistent ideology.

An example from reality was the _Aum Shinrikyo_ cult which made numerous attempts to develop chemical and biological weapons through the 1990s resulting in multiple chemical weapons attacks against civilians including the release of sarin gas into the Tokyo subway in 1995. The "Supreme Truth" of the cult was a belief that Armageddon was inevitable and only those killed by the cult would be saved from their sins. That these cults are the offshoot of sapient ideas about cosmology should leave no question that scorpion behavior is a phenomenon separate from our perspective of what is and is not rational to believe.

Should an agent form a belief that its outer sum reward differs from it continuing to play the game in a cooperative way it becomes a scorpion in its society. We distinguish outer sum problems from pascal's mugging because they are the result of perspective shifts. We agree on the reality of the situation and its probabilities, but we have stopped agreeing on the _ought_ statements of what we should be doing.

### Blue-And-Orange Morality

Finally we come to the most exotic form of disagreement that may result in scorpion behavior: disagreement on the nature of reality itself. When we play a game within a competitive landscape we agree on the axioms, the initial beliefs, of that play and those axioms carry forth the logical conclusions of our decisions. If an agent is playing with different axioms their decisions may be entirely self-consistent but completely orthogonal to our expectations.

They are no longer playing the same game, but our decisions are being made on an overlapping playing field. Even if they are playing for some cooperative social good that their axiomatic representation of what that social good is differs so far from ours their actions are now unpredictable. Blue and orange morality shifts are the extreme of other scorpions because we can no longer agree with the agent about which statements are true and false.

Such moral shifts are possible in any sufficiently complex system which is capable of recognizing its own axiomatic beliefs and positively asserting new ones. This falls into the realm of "unknown unknowns" about the possible moral landscape of superintelligent beings and their ultimate beliefs. As Nietzsche says the Ubermensch creates new values from the vacuum of nihilism, so too can intelligences create new concepts of reality from the vacuum of physical assumptions.

## Playing With Scorpions

In the landscape of game theory where scorpions exist trust can be given freely but it is an act of courage and, in cases, foolishness. In order for society to operate it must rely on the cooperative instincts of its members, but noncooperative behavior restricts the options for cooperation that a society has. The existence of scorpions further informs that no inner group or special cabal can be thought of as truly safe, for the threat of defection still remains.

This indeed colors how our society shapes itself both for good and ill. For schemes and those of evil intent that they cannot truly trust each other has limited their capability for wide spread damage. That social structures will never be fully safe has created opportunities for Machiavellian power to form at its highest reaches and tilt the games that people play away from cooperativity.

It is truly a wonder that society is as stable as it is and perhaps an indication that the rate of both rational and irrational scorpions in society is sufficiently low enough that for most people they are not a concern they are likely to have. On the large scale society does not stop scorpions from beginning their paths of terror, it only stops those paths from spreading too far.

The more access a scorpion has to tools of destruction the more harm they can cause before they are stopped. The more energetic a society becomes the more access to destructive capabilities will be there for scorpions. Although it has largely been possible for society to keep truly dangerous tools from the hands of people bent solely on harm this gets less likely as the capabilities of a society increase.

Eventually the cost of access to our most dangerous tools, be they biological, chemical, nuclear, or just pure kinetics, will exceed society's capability to keep a reign on these. At this point the scorpions transition from individually threatening to society-ending if they have the capacity to continually cause widespread havoc and death. We do not need to concern ourselves with any single technology for this to come to pass, only the combined efforts of society to advance technology. It is a matter of time for a technical tree of development to yield something so uncontrollable and powerful that it easily falls into the hands of scorpions.

### What's At Stake

As an advocate for AI research it may seem odd that I would openly warn of the threat of technology as exacerbating what is a deep underlying issue in society to the point of total collapse. Without having heard the full position this may seem quite a pessimistic conclusion to have come to! I view myself as a pragmatist who faces issues completely without trying to pretend that the problem is not as deep as it looks. However, I am also an optimist in coming to solutions for even thorny problems such as these and AI is the source of that optimism.

We face a double-edged sword with technology and in many ways we are past the point of no return in our development. Our energetic output has so expanded our capabilities that we are changing the biosphere in which we live, pushing ourselves towards a climate collapse. There are so many of us present on this planet that even if we wanted to pump the brakes we can't, there's no controlling the actions of others and we can't brake hard enough anyway.

The risk/reward tradeoff is such that we either fail and burn as a civilization continuing on as we currently are or take drastic measures to right our course. The climate disaster is just one of the many future risks that we face. Our endocrine systems are suffering from exposure to multiple chemical disruptors which we have failed to adequately characterize, dropping birth rates globally and bringing us to the danger of a population collapse.

Our genetic and biological knowledge is just at the edge of being extremely dangerous in its capabilities of producing lethal weapons in labs that could be built in a garage. Our ecosystems are suffering in much the same way; a global extinction event is taking place at the most rapid rate seen in the fossil record. Each of these problems cascade into each other in ways that are not ready to adapt to.

A civilization collapse at this point could mean a human extinction event through the triggering of a nuclear war or such an extreme loss in capabilities that it creates a centuries long dark age and the deaths of billions.

How does AI address these issues? The use of models of our environment gives us access to wisdom we have not had access to before. Our inability to correct our course is related to our inability to appropriately model these complex systems well enough to prove how new solutions will steer us. With enough access to compute and systems that are more useable and steerable with natural language we have the sudden capacity to begin modelling nearly intractable problems and creating new solutions that will interlock in ways that humans previously could have never imagined. Far from killing us directly, AI is posed to save us.

### Defense Against The Dark Arts

But of course, accelerating the advancement of technology throws us headlong back into the problem of scorpions. So let's discuss how AI tools can also create defenses against scorpion dynamics and its contagious effects.

#### Mental Health

Most clearly and effectively in reducing social risk will be through increasing the opportunities people have to receive therapy and mental health treatment. A decrease in the number of extreme mental health crises will drastically reduce the propensity for violence in society by lowering the contagion caused by scorpions spreading damage through society, which in turn causes the activation of more scorpion behavior due to stressors. In the use of AI to increase the availability and effectiveness of treatment people can be returned to social behavior before they become a risk.

Furthermore AI used in behavioral analysis can determine where people are on this spectrum and recommend them to treatment prior to divergent escapes. In other words, instead of using constraints within society to stop the spread of the scorpion contagion after it has already begun an AI-powered mental health system can detect the contagion before it begins. By using AI health tools we can detect the irrational scorpions and redirect the rational scorpions before they become risks to themselves and others.

#### Rising Tides

Another source of "Cornered Animal" behavior in our society is the loss of social support structure. The wealth and prosperity of a civilization truly using AI tools to its advantage will have more than enough to spend on maintaining a standard of living for people such that extremists do not have the broken social structures to form within. When taken care of and provided for the majority of people do not slip between the cracks to start actively having antisocial thoughts. Raising the extreme end of inequality with social programs will reduce the number of people for whom all hope is lost and thereby increase the stability of society.

This of course depends on rapid and effective uses of those resources to support society. This is another place AI agents will excel; the efficient distribution of resources. Highly efficient systems of resource delivery can reduce scarcity across society. Improved construction techniques designed from first principles by algorithms can rapidly build housing, living spaces, and human-adapted communal areas. New materials technologies will simultaneously reduce the cost of these constructions. This will only be fully enabled by science-based policy decisions and integration of AI into governing bodies to streamline decisions and reduce waste.

Capital as a system of distributing resources relies on efficient use of capital. AI technologies are by design efficient at problem solving and discovering solutions in complex spaces. Our adoption of these technologies in every aspect of life will lift humanity that has been otherwise left behind out of despair, but only if we choose to allow it to.

#### Individual Power

Next, capping individual power so that no single party has enough influence to use extreme methods has been the most effective tool at limiting the possibility of nuclear disaster. Because no one person can make the decision of a unilateral nuclear strike it has never occurred. Having safeguards in place on the most dangerous tools available to society will provide more guarantees that such tools are never misused. It should always take multiple decision makers to agree independently outside of the capacity for coercing them as a group to use a tool that is dangerous enough to cause widespread harm.

Limiting individual power for the safety of the masses will take a widespread shift in how society approaches individual power. Cooperative endeavors such as DAOs are preferred in a future model where no single person should be trusted with the authority to use a dangerous tool. Beyond people, safeguards on systems should be cryptographically secure such that those decisions are made ensuring that they have not been tampered with. Humans are slow decision makers but should find places in the system where they can act as a valve controlling the flow of decisions being made, acting to halt progress and utilization of tools in ways which we deem unsafe to society. Security often relies on many decision makers in order to increase the likelihood that any one of those decisions will stop a bad decision from being made. The swiss cheese analogy to stopping breaches is that every system has holes in it, but enough systems stacked on top of each other cover the holes until there are no more gaps.

In this future, all decisions beyond a certain capability threshold are made by the whole chain with fail-safes in place to ensure that any disagreement stops the usage. AI projects will need to be bounded within experimental and simulation regimes with known safety margin by consent of the governance chain. All of these choices will not be made by humans alone, but set in layers of algorithms which have been designed to filter problems up to decision makers before they occur. With enough of these filters in place and mathematical frameworks to prove their effectiveness we can create interlocking systems of decisions which have astronomically low theoretical failure rates.

Each system of joined decisions is a balance between effectiveness and restrictiveness. With AI managing the policy between such interlocking systems these systems can be constantly adapting, optimizing toward riding the balancing point between these two extremes until they have reached the theoretical optimum of intelligent decision making. 

#### Capabilities Monitoring

Louis Brandeis said that sunlight is the best disinfectant meaning that transparency is the best cure for corruption. It is also the case that scorpions thrive where they can hide their intent for long enough to gain power to be dangerous. In the short term this is acquisition of tools and resources that can effectively cause damage. We should also not limit our beliefs as to what that damage might entail. A scorpion's access is best kept contained to minimize their capabilities by creating threat signatures with AI algorithms and applying those to behavior. Internal to AI systems these can be directly attached to each layer of the algorithm for extensive monitoring of the system. For human beings they leave online trails demonstrating their increasing threat through increase of their capabilities.

In [General Intelligence](https://teague.info/article/agi) I discuss that the attention an agent pays to its environment is an indicator of its internal motivations, and these keys to behavior can be leveraged as early warning systems for scorpions in a _Minority Report_ AI system. I find myself hesitating writing these ideas down as I know the exceptional leverage that such monitoring will give those who control it. However, in the world I am imagining allowing a scorpion free access to extend its capabilities could be a _civilization-level_ risk.

If biological weapons can be made in a garage laboratory it is imperative they be stopped before they are started. If military drones were assembled in a factory we would not allow an individual to run their operation without supervision. If an asteroid can be accelerated at Earth is is imperative that any space vehicle capable of doing it is accounted for. As the energy of our civilization increases so to do the lower end of the capabilities of an individual become possible to cause catastrophe. If individuals have the power to cause signficant damage society can no longer afford to let individuals go fully unsupervised.

As society grows in its capabilities we must become increasingly aware of our weak points before scorpions take advantage of them. AI tools can help us monitor possible threat scenarios and explore new risks just as white hat security hackers attempt to find new flaws in security before they begin. If we do not choose to actively seek out the flaws in our system and fix them then as our capabilities increase there will be some contingent of society who choose to do so without our consent and with intent to cause real harm. Right now we are living on the cusp of enormous power; we should be ready to responsibly use it.

#### Spreading Out

Not least of our options in dealing with scorpions is to reduce the existential risk caused by our civilization having only one home. With every fiber of our beings we should make an effort to defend Earth and transform it into a place that all beings may live on, but even ignoring the risks from within we cannot ignore the risks from without. A single high speed asteroid from deep space with an unlucky enough trajectory could destroy Earth. A single geological event could render much of Earth uninhabitable for humans. Even without concerns of our own power, nature still has power enough to spare to cause us serious injury unannounced.

The best strategy to stay safe as a civilization is to make sure that no single blow can destroy you. With as much effort as we can spare humanity advancing to the stars, both our neighboring planets and building space habitats, is the single most effective strategy we have to mitigating existential risk. Being spread out gives you time to react when things go wrong. Being spread out limits the scope of damage from losing any one habitat for humanity. Being spread out means that the pressures of being all together are reduced and choosing to leave is a real option over self-destructing.

Humanity must make it to the stars. We must do so because it is our destiny. We must do so because it ensures our survival as a civilization regardless of the disasters we may face in the future. Those of us brave and reckless enough to face the dangers of scorpions down on Earth will stay and keep the hearth burning at home.

### AI scorpions

Our last point to cover is the potential for AI to become scorpions. We have alluded to this and for many it is a source of enormous fear of these systems. First I will say that the scorpion problem is a general problem of sentience but the vast majority of deployed AI systems will not be sentient. In order for an AI to frame a problem in a truly unexpected way it must have decoupled itself from its training and reward circuits and be operating with a part of its consciousness actively suppressing those signals and asserting new ones. This, as yet, takes a cognitive architecture we do not know how to build. There is an unknown element to sentience that we do not currently know how to build which makes it impossible to predict when such a thing could be possible. It is either easy and will arrive soon by scaling our models larger or such a difficult balance that it will take decades of research still even with advanced tools at our disposal.

Some make it seem inevitable that sentience will arise in machine consciousness. I will again make the distinction between consciousness and sentience: consciousness is awareness, sentience is being decoupled from the underlying reward hardware of a brain and free to create new reward pathways. It is not inevitable and despite ourselves as proof that it is possible we do not know what it will take. On the road to developing machine sentience we may arrive at multiple unstable solutions to the problem which will act as scorpions to us. Beings which do strive to optimize toward totally alien objectives that make them orthogonally moral to us. It is therefore in our best interests for our solutions to the scorpion problem at a social scale to include machine systems and not just their human operators in the network of regulatory systems that we establish to detect scorpions.

While it is true that AI capabilities can rapidly extend beyond human ones, by establishing solutions to scorpions now we will have made a framework of interlocking systems that cannot be exploited quickly and will detect and mitigate power seeking behavior rapidly. And as I stated in [Limits of Thought](https://teague.info/article/limitsofthought) an AI system is just another system with limitations to its capabilities imposed by computer science and physics which we can predict ahead of time. This is why we must begin now, because we do not know when machine sentience will arise but we also know that the more capabilities we extend with AI the more defensive structures we will have in place to stop AI scorpions. The double-edged sword of technology can cut only one way if we actively choose to blunt one side of the blade.
