[{
	"id": "intro",
	"title": "Hello World!",
  "image": "article0.png",
	"excerpt": "I've been an avid futurist since my early teens. As a psuedonymous lurker on forums and reddit posts I've explored the philosophy and science to find not just the deepest meaning of being human, but of all possible intelligences across the Universe. As an engineer I've worked to lift humanity to the stars and bring new understanding to our own brains structure and function. Let's learn together what makes the light of consciousness truly worth keeping aflame."
}, {
	"id": "frameskipping",
	"title": "Frame-skipping and Clippy Safety",
  "image": "article1.png",
	"excerpt": "'Frame-skipping' AIs try to manipulate their rewards in unintended ways. They should work within their designated optimization frame, but instead, they bypass obstacles by working outside this frame. AI run on real hardware with real vulnerabilities. Frame-skipping AIs can cheat by modifying their reward inputs directly, such as altering memory locations, exploiting software and hardware bugs, or breaking into reward-controlling infrastructure. Their own hardware will be the easiest and first thing they will find weaknesses in exploiting their objective function."
}, {
	"id": "limitsofthought",
	"title": "The Limits of Thought",
  "image": "article2.png",
	"excerpt": "It is a mistake to consider intelligence too abstractly. Any assumption of formlessness builds intuitions that are nonphysical. Examples of this are concepts that small-scale AI projects might be sources for an intelligence explosion or that once formed an AGI may become a distributed network in a viral way such that it is impossible to contain. Here I will begin to physically ground these ideas by elaborating on the computational bounds that all intelligences must obey."
}, {
	"id": "agi",
	"title": "General Intelligence",
  "image": "article3.png",
  "excerpt": "In this article I describe the modelling of an intelligent actor broadly, connecting both humans and AGI. This is presented as a model for how actors can model other actors in their world and infer agency when the agent is not fully observed. This is intended to be a basis by which we can discuss how general intelligences perceive and interact with their world in at an abstract enough level for the description to be applicable to approaches not yet attempted."
}, {
	"id": "free",
	"title": "Free Relative Energy Ethics",
  "image": "article4.png",
  "excerpt": "In bringing forth new minds in our machines we are faced with these deep moral questions of who we are, who we aspire to be, and what decisions we need to make to ensure that our civilization prospers into the future. Our goal in making an ethical machine is not to create an actor which is enslaved to humanity or its past preconceptions about how things ought to be. Our goal is to make an actor that converges over time to a morally good position and thus our goal is to define what that morally good position could be."
}]
